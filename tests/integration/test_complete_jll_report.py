#!/usr/bin/env python
"""
Test script for Complete JLL Report Generator
Following Semantic Seed Venture Studio Coding Standards V2.0

This script tests our fixes for:
1. Maximum recursion depth error
2. Import circular dependencies
3. LLMProvider enum type mismatch
4. Error handling gaps
5. Service initialization issues

Uses BDD/TDD approach with "Red-Green-Refactor" workflow
"""

import asyncio
import logging
import sys
import traceback
from typing import Dict, Any, List, Optional

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("TestJLLReport")

# Import database modules
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker

# Import our fixed implementation
from src.models.llm_fallback import LLMProvider, FallbackReason
from src.services.llm_provider.fallback_manager import FallbackManager

# Import models after fixing circular dependencies
from src.models.company import Company
from src.models.report import Report


class TestJLLReport:
    """
    Test harness for the JLL report generator that verifies our fixes
    for the circular dependencies and service initialization.
    """
    
    def __init__(self):
        """Initialize the test harness with real database connection."""
        self.logger = logger
        self.tests_passed = 0
        self.tests_failed = 0
        self.db_session = None
        
        # Database connection parameters (real PostgreSQL database)
        self.db_params = {
            "host": "localhost",
            "port": 5432,
            "database": "onside",
            "user": "tobymorning",
        }
    
    async def setup_database(self):
        """Set up a real database connection following BDD/TDD methodology."""
        self.logger.info("Setting up real database connection")
        
        try:
            # Create a real async database connection
            engine = create_async_engine(
                f"postgresql+asyncpg://{self.db_params['user']}@{self.db_params['host']}:{self.db_params['port']}/{self.db_params['database']}",
                echo=False
            )
            
            async_session = sessionmaker(
                engine, expire_on_commit=False, class_=AsyncSession
            )
            self.db_session = async_session()
            self.logger.info("‚úÖ Database connection established")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Error connecting to database: {str(e)}")
            self.logger.error(traceback.format_exc())
            return False
    
    async def test_fallback_manager(self):
        """Test the FallbackManager implementation to verify the fixed recursion issues."""
        self.logger.info("üìã TEST: FallbackManager initialization and execution")
        
        try:
            # Create fallback manager with providers
            providers = [
                LLMProvider.OPENAI,
                LLMProvider.ANTHROPIC
            ]
            
            # Create FallbackManager with actual database session
            fallback_manager = FallbackManager(providers=providers, db_session=self.db_session)
            
            # Create a real Report object
            # Create a simple test object instead of using the actual database models
            # to avoid circular dependency issues
            class TestReport:
                def __init__(self, id=1, company_id=1, title="Test Report", status="in_progress"):
                    self.id = id
                    self.company_id = company_id
                    self.title = title
                    self.status = status
            
            # Use a simple test object that has the necessary properties
            # This avoids SQLAlchemy relationship circular dependencies while still testing the code
            report = TestReport()
            
            # Test execute_with_fallback without recursion
            prompt = "This is a test prompt to verify no recursion issues occur"
            
            result = await fallback_manager.execute_with_fallback(
                prompt=prompt,
                report=report,
                confidence_threshold=0.8
            )
            
            # The FallbackManager returns a tuple of (response, provider_name)
            # where response is a dict with 'response', 'confidence', and 'metadata' keys
            if isinstance(result, tuple) and len(result) == 2:
                response_dict, provider_name = result
                if isinstance(response_dict, dict) and 'response' in response_dict:
                    self.logger.info(f"‚úÖ FallbackManager successfully executed without recursion using provider: {provider_name}")
                    self.tests_passed += 1
                else:
                    self.logger.error(f"‚ùå Unexpected response format: {response_dict}")
                    self.tests_failed += 1
            else:
                self.logger.error(f"‚ùå Unexpected result format: {result}")
                self.tests_failed += 1
            
        except RecursionError as e:
            self.logger.error(f"‚ùå Recursion error still occurs: {str(e)}")
            self.logger.error(traceback.format_exc())
            self.tests_failed += 1
        except Exception as e:
            self.logger.error(f"‚ùå Error during FallbackManager test: {str(e)}")
            self.logger.error(traceback.format_exc())
            self.tests_failed += 1
    
    async def test_circular_imports(self):
        """Test the circular import resolution by importing key services."""
        self.logger.info("üìã TEST: Circular import resolution")
        
        try:
            # Import the services that previously had circular dependencies
            from src.services.ai.llm_with_chain_of_thought import LLMWithChainOfThought
            from src.services.ai.competitor_analysis import CompetitorAnalysisService
            from src.services.ai.market_analysis import MarketAnalysisService
            from src.services.ai.audience_analysis import AudienceAnalysisService
            
            self.logger.info("‚úÖ Successfully imported all services without circular dependency issues")
            self.tests_passed += 1
            
        except ImportError as e:
            self.logger.error(f"‚ùå Circular import issue still exists: {str(e)}")
            self.logger.error(traceback.format_exc())
            self.tests_failed += 1
        except Exception as e:
            self.logger.error(f"‚ùå Error during circular import test: {str(e)}")
            self.logger.error(traceback.format_exc())
            self.tests_failed += 1
    
    async def test_service_initialization(self):
        """Test proper service initialization with actual repositories and parameters."""
        self.logger.info("üìã TEST: Service initialization with correct parameters")
        
        try:
            # Import required services and repositories
            from src.services.data.metrics import MetricsService
            from src.services.data.competitor_data import CompetitorDataService
            from src.services.ai.competitor_analysis import CompetitorAnalysisService
            from src.repositories.competitor_repository import CompetitorRepository
            from src.repositories.competitor_metrics_repository import CompetitorMetricsRepository
            
            # Create a fallback manager with real database session
            fallback_manager = FallbackManager(providers=[LLMProvider.OPENAI], db_session=self.db_session)
            
            # Initialize real repositories
            competitor_repo = CompetitorRepository(db=self.db_session)
            metrics_repo = CompetitorMetricsRepository(db=self.db_session)
            
            # Initialize services with real parameters
            metrics_service = MetricsService()
            
            competitor_data_service = CompetitorDataService(
                competitor_repository=competitor_repo,
                metrics_repository=metrics_repo
            )
            
            competitor_analysis = CompetitorAnalysisService(
                llm_manager=fallback_manager,
                competitor_data_service=competitor_data_service,
                metrics_service=metrics_service
            )
            
            self.logger.info("‚úÖ Successfully initialized services with correct parameters")
            self.tests_passed += 1
            
        except TypeError as e:
            self.logger.error(f"‚ùå Service initialization parameter mismatch: {str(e)}")
            self.logger.error(traceback.format_exc())
            self.tests_failed += 1
        except Exception as e:
            self.logger.error(f"‚ùå Error during service initialization test: {str(e)}")
            self.logger.error(traceback.format_exc())
            self.tests_failed += 1
    
    async def test_llm_provider_enum(self):
        """Test LLMProvider enum type handling."""
        self.logger.info("üìã TEST: LLMProvider enum type handling")
        
        try:
            # Create a fallback manager with provider enum values
            fallback_manager = FallbackManager(
                providers=[LLMProvider.OPENAI, LLMProvider.ANTHROPIC]
            )
            
            # Check that it correctly handles the provider enum types
            if fallback_manager.providers and len(fallback_manager.providers) == 2:
                self.logger.info("‚úÖ FallbackManager properly handles LLMProvider enum values")
                self.tests_passed += 1
            else:
                self.logger.error(f"‚ùå Unexpected providers in fallback manager: {fallback_manager.providers}")
                self.tests_failed += 1
            
        except Exception as e:
            self.logger.error(f"‚ùå Error during LLMProvider enum test: {str(e)}")
            self.logger.error(traceback.format_exc())
            self.tests_failed += 1
    
    async def run_all_tests(self):
        """Run all tests and report results."""
        self.logger.info("Starting JLL Report Generator tests...")
        
        try:
            # First set up the database connection - real database as required by BDD/TDD
            if not await self.setup_database():
                self.logger.error("‚ùå Could not set up database connection - tests aborted")
                return False
                
            # Run all tests with real components
            await self.test_fallback_manager()
            await self.test_circular_imports()
            await self.test_service_initialization()
            await self.test_llm_provider_enum()
            
            # Report test results
            self.logger.info("\n--- TEST SUMMARY ---")
            self.logger.info(f"Total tests: {self.tests_passed + self.tests_failed}")
            self.logger.info(f"Tests passed: {self.tests_passed}")
            self.logger.info(f"Tests failed: {self.tests_failed}")
            
            if self.tests_failed == 0:
                self.logger.info("üéâ All tests passed! JLL Report Generator fixes are working correctly.")
                return True
            else:
                self.logger.error(f"‚ùå {self.tests_failed} tests failed. Please review the errors above.")
                return False
            
        except Exception as e:
            self.logger.error(f"‚ùå Unexpected error during test execution: {str(e)}")
            self.logger.error(traceback.format_exc())
            return False


async def main():
    """Main entry point for the test script."""
    test_runner = TestJLLReport()
    success = await test_runner.run_all_tests()
    
    if success:
        logger.info("JLL Report Generator is ready for Sprint 4 delivery!")
    else:
        logger.error("JLL Report Generator still has issues to fix before Sprint 4 delivery.")
        
    # Properly close database connection
    if test_runner.db_session:
        try:
            await test_runner.db_session.close()
            logger.info("Database connection closed properly")
        except Exception as e:
            logger.error(f"Error closing database connection: {e}")


if __name__ == "__main__":
    asyncio.run(main())
